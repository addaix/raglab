{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config2py import config_getter\n",
    "OPENAI_API_KEY = config_getter(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download the necessary NLTK data files (only needed once)\n",
    "nltk.download('punkt')\n",
    "# Segment the text into sentences\n",
    "sentence_splits = sent_tokenize\n",
    "sentence_splits.__name__ = \"sentence_splits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from config2py import config_getter\n",
    "\n",
    "OPENAI_API_KEY = config_getter(\"OPENAI_API_KEY\")\n",
    "\n",
    "def sentence_embeddings(meaningful_sentences, api_key):\n",
    "    embeddings_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\", dimensions=512)\n",
    "    return np.array(embeddings_model.embed_documents(meaningful_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def consecutive_cosines(sentence_embeddings):\n",
    "    z = zip(sentence_embeddings, sentence_embeddings[1:])\n",
    "    cosines = [cosine_similarity([a], [b])[0][0] for a,b in z]\n",
    "    return cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "def cuts(consecutive_cosines, **kwargs):\n",
    "    neg_cosines = [-c for c in consecutive_cosines]\n",
    "    peaks_idx, _ = find_peaks(neg_cosines, **kwargs)\n",
    "    return peaks_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_chunk_ids(cuts):\n",
    "    segments_ids = []\n",
    "    start = 0\n",
    "    for stop in cuts:\n",
    "        segments_ids.append((start, stop+1))\n",
    "        start = stop + 1\n",
    "    segments_ids.append((start, -1))\n",
    "    return segments_ids\n",
    "\n",
    "def character_chunk_ids(sentence_chunk_ids, sentence_splits):\n",
    "    character_chunk_ids = []\n",
    "    for start, stop in sentence_chunk_ids:\n",
    "        character_chunk_ids.append((\n",
    "            (sum(len(sentence) for sentence in sentence_splits[:start])+1),\n",
    "            (sum(len(sentence) for sentence in sentence_splits[:stop])+1)\n",
    "            ))\n",
    "    return character_chunk_ids\n",
    "\n",
    "def chunk_text(character_chunk_ids, text):\n",
    "    return [text[start:stop] for start, stop in character_chunk_ids]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "def is_meaningful(sentence, language='english'):\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    words = word_tokenize(sentence)\n",
    "    # Filter out punctuation and stopwords\n",
    "    meaningful_words = [word for word in words if word.lower() not in stop_words and word not in punctuation]\n",
    "    return len(meaningful_words) > 0\n",
    "\n",
    "def meaningful_sentences(sentence_splits):\n",
    "    return [sentence for sentence in sentence_splits if is_meaningful(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"341pt\" height=\"1196pt\"\n",
       " viewBox=\"0.00 0.00 340.50 1196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1192)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1192 336.5,-1192 336.5,4 -4,4\"/>\n",
       "<!-- sentence_splits -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>sentence_splits</title>\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-1022.3\" font-family=\"Times,serif\" font-size=\"14.00\">sentence_splits</text>\n",
       "</g>\n",
       "<!-- meaningful_sentences_ -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>meaningful_sentences_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"180.5,-972 36.5,-972 36.5,-936 180.5,-936 180.5,-972\"/>\n",
       "<text text-anchor=\"middle\" x=\"108.5\" y=\"-950.3\" font-family=\"Times,serif\" font-size=\"14.00\">meaningful_sentences_</text>\n",
       "</g>\n",
       "<!-- sentence_splits&#45;&gt;meaningful_sentences_ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>sentence_splits&#45;&gt;meaningful_sentences_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.37,-1007.88C180.33,-998.72 161.63,-987.34 145.44,-977.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"147.1,-974.4 136.74,-972.19 143.46,-980.38 147.1,-974.4\"/>\n",
       "</g>\n",
       "<!-- character_chunk_ids_ -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>character_chunk_ids_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"277,-252 142,-252 142,-216 277,-216 277,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"209.5\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">character_chunk_ids_</text>\n",
       "</g>\n",
       "<!-- sentence_splits&#45;&gt;character_chunk_ids_ -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>sentence_splits&#45;&gt;character_chunk_ids_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.95,-1007.65C234.38,-981.02 245.5,-928.4 245.5,-883 245.5,-883 245.5,-883 245.5,-377 245.5,-335.78 231.07,-289.83 220.48,-261.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.66,-260.19 216.79,-252.13 217.14,-262.72 223.66,-260.19\"/>\n",
       "</g>\n",
       "<!-- text -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>text</title>\n",
       "<text text-anchor=\"middle\" x=\"305.5\" y=\"-1166.3\" font-family=\"Times,serif\" font-size=\"14.00\">text</text>\n",
       "</g>\n",
       "<!-- sentence_splits_ -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>sentence_splits_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"276,-1116 171,-1116 171,-1080 276,-1080 276,-1116\"/>\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-1094.3\" font-family=\"Times,serif\" font-size=\"14.00\">sentence_splits_</text>\n",
       "</g>\n",
       "<!-- text&#45;&gt;sentence_splits_ -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>text&#45;&gt;sentence_splits_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M285.23,-1151.7C275,-1142.97 262.44,-1132.24 251.32,-1122.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"253.41,-1119.94 243.54,-1116.1 248.87,-1125.26 253.41,-1119.94\"/>\n",
       "</g>\n",
       "<!-- chunk_text_ -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>chunk_text_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"299,-108 216,-108 216,-72 299,-72 299,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"257.5\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">chunk_text_</text>\n",
       "</g>\n",
       "<!-- text&#45;&gt;chunk_text_ -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>text&#45;&gt;chunk_text_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M305.5,-1151.95C305.5,-1125.29 305.5,-1072.11 305.5,-1027 305.5,-1027 305.5,-1027 305.5,-233 305.5,-190.87 286.3,-145.23 272.19,-117.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.18,-115.54 267.45,-108.29 268.97,-118.78 275.18,-115.54\"/>\n",
       "</g>\n",
       "<!-- language -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>language</title>\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-1166.3\" font-family=\"Times,serif\" font-size=\"14.00\">language=</text>\n",
       "</g>\n",
       "<!-- language&#45;&gt;sentence_splits_ -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>language&#45;&gt;sentence_splits_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.5,-1151.7C223.5,-1143.98 223.5,-1134.71 223.5,-1126.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227,-1126.1 223.5,-1116.1 220,-1126.1 227,-1126.1\"/>\n",
       "</g>\n",
       "<!-- sentence_splits_&#45;&gt;sentence_splits -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>sentence_splits_&#45;&gt;sentence_splits</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.5,-1079.7C223.5,-1071.98 223.5,-1062.71 223.5,-1054.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227,-1054.1 223.5,-1044.1 220,-1054.1 227,-1054.1\"/>\n",
       "</g>\n",
       "<!-- meaningful_sentences -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>meaningful_sentences</title>\n",
       "<text text-anchor=\"middle\" x=\"71.5\" y=\"-878.3\" font-family=\"Times,serif\" font-size=\"14.00\">meaningful_sentences</text>\n",
       "</g>\n",
       "<!-- sentence_embeddings_ -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>sentence_embeddings_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143,-828 0,-828 0,-792 143,-792 143,-828\"/>\n",
       "<text text-anchor=\"middle\" x=\"71.5\" y=\"-806.3\" font-family=\"Times,serif\" font-size=\"14.00\">sentence_embeddings_</text>\n",
       "</g>\n",
       "<!-- meaningful_sentences&#45;&gt;sentence_embeddings_ -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>meaningful_sentences&#45;&gt;sentence_embeddings_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.5,-863.7C71.5,-855.98 71.5,-846.71 71.5,-838.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75,-838.1 71.5,-828.1 68,-838.1 75,-838.1\"/>\n",
       "</g>\n",
       "<!-- meaningful_sentences_&#45;&gt;meaningful_sentences -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>meaningful_sentences_&#45;&gt;meaningful_sentences</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.35,-935.7C95.1,-927.64 89.94,-917.89 85.23,-908.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.31,-907.31 80.54,-900.1 82.12,-910.58 88.31,-907.31\"/>\n",
       "</g>\n",
       "<!-- sentence_embeddings -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>sentence_embeddings</title>\n",
       "<text text-anchor=\"middle\" x=\"71.5\" y=\"-734.3\" font-family=\"Times,serif\" font-size=\"14.00\">sentence_embeddings</text>\n",
       "</g>\n",
       "<!-- consecutive_cosines_ -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>consecutive_cosines_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138.5,-684 4.5,-684 4.5,-648 138.5,-648 138.5,-684\"/>\n",
       "<text text-anchor=\"middle\" x=\"71.5\" y=\"-662.3\" font-family=\"Times,serif\" font-size=\"14.00\">consecutive_cosines_</text>\n",
       "</g>\n",
       "<!-- sentence_embeddings&#45;&gt;consecutive_cosines_ -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>sentence_embeddings&#45;&gt;consecutive_cosines_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.5,-719.7C71.5,-711.98 71.5,-702.71 71.5,-694.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75,-694.1 71.5,-684.1 68,-694.1 75,-694.1\"/>\n",
       "</g>\n",
       "<!-- api_key -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>api_key</title>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-878.3\" font-family=\"Times,serif\" font-size=\"14.00\">api_key</text>\n",
       "</g>\n",
       "<!-- api_key&#45;&gt;sentence_embeddings_ -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>api_key&#45;&gt;sentence_embeddings_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159.12,-863.88C143.96,-854.72 125.09,-843.34 108.76,-833.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.36,-830.36 99.99,-828.19 106.74,-836.35 110.36,-830.36\"/>\n",
       "</g>\n",
       "<!-- sentence_embeddings_&#45;&gt;sentence_embeddings -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>sentence_embeddings_&#45;&gt;sentence_embeddings</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.5,-791.7C71.5,-783.98 71.5,-774.71 71.5,-766.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75,-766.1 71.5,-756.1 68,-766.1 75,-766.1\"/>\n",
       "</g>\n",
       "<!-- consecutive_cosines -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>consecutive_cosines</title>\n",
       "<text text-anchor=\"middle\" x=\"71.5\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">consecutive_cosines</text>\n",
       "</g>\n",
       "<!-- cuts_ -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>cuts_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"178.5,-540 124.5,-540 124.5,-504 178.5,-504 178.5,-540\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.5\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">cuts_</text>\n",
       "</g>\n",
       "<!-- consecutive_cosines&#45;&gt;cuts_ -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>consecutive_cosines&#45;&gt;cuts_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M91.28,-575.7C101.25,-566.97 113.51,-556.24 124.36,-546.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.73,-549.32 131.95,-540.1 122.12,-544.06 126.73,-549.32\"/>\n",
       "</g>\n",
       "<!-- consecutive_cosines_&#45;&gt;consecutive_cosines -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>consecutive_cosines_&#45;&gt;consecutive_cosines</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.5,-647.7C71.5,-639.98 71.5,-630.71 71.5,-622.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75,-622.1 71.5,-612.1 68,-622.1 75,-622.1\"/>\n",
       "</g>\n",
       "<!-- cuts -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>cuts</title>\n",
       "<text text-anchor=\"middle\" x=\"151.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">cuts</text>\n",
       "</g>\n",
       "<!-- sentence_chunk_ids_ -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>sentence_chunk_ids_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"217.5,-396 85.5,-396 85.5,-360 217.5,-360 217.5,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.5\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">sentence_chunk_ids_</text>\n",
       "</g>\n",
       "<!-- cuts&#45;&gt;sentence_chunk_ids_ -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>cuts&#45;&gt;sentence_chunk_ids_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.5,-431.7C151.5,-423.98 151.5,-414.71 151.5,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155,-406.1 151.5,-396.1 148,-406.1 155,-406.1\"/>\n",
       "</g>\n",
       "<!-- kwargs -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>kwargs</title>\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">kwargs=</text>\n",
       "</g>\n",
       "<!-- kwargs&#45;&gt;cuts_ -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>kwargs&#45;&gt;cuts_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177.1,-575.7C173.23,-567.73 168.55,-558.1 164.26,-549.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.33,-547.57 159.81,-540.1 161.03,-550.63 167.33,-547.57\"/>\n",
       "</g>\n",
       "<!-- cuts_&#45;&gt;cuts -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>cuts_&#45;&gt;cuts</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.5,-503.7C151.5,-495.98 151.5,-486.71 151.5,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155,-478.1 151.5,-468.1 148,-478.1 155,-478.1\"/>\n",
       "</g>\n",
       "<!-- sentence_chunk_ids -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>sentence_chunk_ids</title>\n",
       "<text text-anchor=\"middle\" x=\"153.5\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">sentence_chunk_ids</text>\n",
       "</g>\n",
       "<!-- sentence_chunk_ids&#45;&gt;character_chunk_ids_ -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>sentence_chunk_ids&#45;&gt;character_chunk_ids_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.34,-287.7C173.99,-279.39 182.08,-269.28 189.39,-260.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.3,-262.1 195.82,-252.1 186.84,-257.73 192.3,-262.1\"/>\n",
       "</g>\n",
       "<!-- sentence_chunk_ids_&#45;&gt;sentence_chunk_ids -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>sentence_chunk_ids_&#45;&gt;sentence_chunk_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.99,-359.7C152.21,-351.98 152.48,-342.71 152.73,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.22,-334.2 153.01,-324.1 149.23,-334 156.22,-334.2\"/>\n",
       "</g>\n",
       "<!-- character_chunk_ids -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>character_chunk_ids</title>\n",
       "<text text-anchor=\"middle\" x=\"211.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">character_chunk_ids</text>\n",
       "</g>\n",
       "<!-- character_chunk_ids&#45;&gt;chunk_text_ -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>character_chunk_ids&#45;&gt;chunk_text_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.87,-143.7C228.22,-135.56 234.7,-125.69 240.61,-116.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"243.69,-118.38 246.26,-108.1 237.84,-114.54 243.69,-118.38\"/>\n",
       "</g>\n",
       "<!-- character_chunk_ids_&#45;&gt;character_chunk_ids -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>character_chunk_ids_&#45;&gt;character_chunk_ids</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M209.99,-215.7C210.21,-207.98 210.48,-198.71 210.73,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"214.22,-190.2 211.01,-180.1 207.23,-190 214.22,-190.2\"/>\n",
       "</g>\n",
       "<!-- chunk_text -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>chunk_text</title>\n",
       "<text text-anchor=\"middle\" x=\"257.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">chunk_text</text>\n",
       "</g>\n",
       "<!-- chunk_text_&#45;&gt;chunk_text -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>chunk_text_&#45;&gt;chunk_text</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M257.5,-71.7C257.5,-63.98 257.5,-54.71 257.5,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"261,-46.1 257.5,-36.1 254,-46.1 261,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fbfa50b08e0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from meshed import DAG\n",
    "funcs = [consecutive_cosines,\n",
    "         sentence_embeddings,\n",
    "        meaningful_sentences,\n",
    "         cuts,\n",
    "         sentence_chunk_ids,\n",
    "        character_chunk_ids,\n",
    "         sentence_splits,\n",
    "                chunk_text,\n",
    "        ]\n",
    "\n",
    "dag = DAG(funcs)\n",
    "dag.dot_digraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_keys(documents, api_key, language='english'):\n",
    "    segment_keys= []\n",
    "    for doc_name, text in documents.items():\n",
    "        character_chunk_ids = dag[:\"character_chunk_ids\"](language=language, text=text, api_key=api_key)\n",
    "        for start, stop in character_chunk_ids:\n",
    "            segment_keys.append((doc_name, start, stop))\n",
    "    return segment_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doc1', 1, 366), ('doc1', 366, 597)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"\"\"\n",
    "Monsters, Inc. is a 2001 American computer-animated comedy film produced by Pixar Animation Studios and distributed by Walt Disney Pictures. Featuring the voices of John Goodman, Billy Crystal, Steve Buscemi, James Coburn, and Jennifer Tilly, the film was directed by Pete Docter in his directorial debut, and executive produced by John Lasseter and Andrew Stanton. The film centers on two monsters – James P. \"Sulley\" Sullivan and his one-eyed partner and best friend Mike Wazowski – employed at the titular energy-producing factory Monsters, Inc, which generates power by scaring human children. The monster world believes that children are toxic, and when a small child enters the factory, Sulley and Mike must return her home before it is too late.\"\"\" \n",
    "# dag(text=txt, api_key=OPENAI_API_KEY)\n",
    "\n",
    "segment_keys({\"doc1\": txt}, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First testing of retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"511pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 511.00 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 507,-472 507,4 -4,4\"/>\n",
       "<!-- query -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>query</title>\n",
       "<text text-anchor=\"middle\" x=\"386.5\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">query</text>\n",
       "</g>\n",
       "<!-- query_embedding_ -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>query_embedding_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"447.5,-252 325.5,-252 325.5,-216 447.5,-216 447.5,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"386.5\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">query_embedding_</text>\n",
       "</g>\n",
       "<!-- query&#45;&gt;query_embedding_ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>query&#45;&gt;query_embedding_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M386.5,-287.7C386.5,-279.98 386.5,-270.71 386.5,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"390,-262.1 386.5,-252.1 383,-262.1 390,-262.1\"/>\n",
       "</g>\n",
       "<!-- user_query -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>user_query</title>\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">user_query</text>\n",
       "</g>\n",
       "<!-- query_ -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>query_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"413.5,-396 359.5,-396 359.5,-360 413.5,-360 413.5,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"386.5\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">query_</text>\n",
       "</g>\n",
       "<!-- user_query&#45;&gt;query_ -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>user_query&#45;&gt;query_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.59,-431.7C350.42,-423.3 358.76,-413.07 366.26,-403.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"368.97,-406.07 372.57,-396.1 363.54,-401.65 368.97,-406.07\"/>\n",
       "</g>\n",
       "<!-- process_function -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>process_function</title>\n",
       "<text text-anchor=\"middle\" x=\"444.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">process_function=</text>\n",
       "</g>\n",
       "<!-- process_function&#45;&gt;query_ -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>process_function&#45;&gt;query_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M430.16,-431.7C423.21,-423.3 414.73,-413.07 407.1,-403.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"409.75,-401.57 400.67,-396.1 404.36,-406.04 409.75,-401.57\"/>\n",
       "</g>\n",
       "<!-- query_&#45;&gt;query -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>query_&#45;&gt;query</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M386.5,-359.7C386.5,-351.98 386.5,-342.71 386.5,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"390,-334.1 386.5,-324.1 383,-334.1 390,-334.1\"/>\n",
       "</g>\n",
       "<!-- query_embedding -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>query_embedding</title>\n",
       "<text text-anchor=\"middle\" x=\"386.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">query_embedding</text>\n",
       "</g>\n",
       "<!-- top_k_segments_ -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>top_k_segments_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"260.5,-108 148.5,-108 148.5,-72 260.5,-72 260.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"204.5\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">top_k_segments_</text>\n",
       "</g>\n",
       "<!-- query_embedding&#45;&gt;top_k_segments_ -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>query_embedding&#45;&gt;top_k_segments_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M341.98,-143.88C316.77,-134.18 285.05,-121.98 258.43,-111.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.47,-108.39 248.88,-108.07 256.95,-114.92 259.47,-108.39\"/>\n",
       "</g>\n",
       "<!-- query_embedding_&#45;&gt;query_embedding -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>query_embedding_&#45;&gt;query_embedding</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M386.5,-215.7C386.5,-207.98 386.5,-198.71 386.5,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"390,-190.1 386.5,-180.1 383,-190.1 390,-190.1\"/>\n",
       "</g>\n",
       "<!-- top_k_segments -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>top_k_segments</title>\n",
       "<text text-anchor=\"middle\" x=\"204.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">top_k_segments</text>\n",
       "</g>\n",
       "<!-- doc_embeddings -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>doc_embeddings</title>\n",
       "<text text-anchor=\"middle\" x=\"54.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">doc_embeddings</text>\n",
       "</g>\n",
       "<!-- doc_embeddings&#45;&gt;top_k_segments_ -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>doc_embeddings&#45;&gt;top_k_segments_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M91.19,-143.88C111.52,-134.39 136.97,-122.51 158.6,-112.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"160.34,-115.47 167.93,-108.07 157.38,-109.13 160.34,-115.47\"/>\n",
       "</g>\n",
       "<!-- k -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>k</title>\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">k=</text>\n",
       "</g>\n",
       "<!-- k&#45;&gt;top_k_segments_ -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>k&#45;&gt;top_k_segments_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.86,-143.7C172.73,-135.47 179.87,-125.48 186.34,-116.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.32,-118.28 192.28,-108.1 183.62,-114.21 189.32,-118.28\"/>\n",
       "</g>\n",
       "<!-- distance_metric -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>distance_metric</title>\n",
       "<text text-anchor=\"middle\" x=\"255.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">distance_metric=</text>\n",
       "</g>\n",
       "<!-- distance_metric&#45;&gt;top_k_segments_ -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>distance_metric&#45;&gt;top_k_segments_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M242.89,-143.7C236.9,-135.47 229.62,-125.48 223.02,-116.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.68,-114.13 216.96,-108.1 220.02,-118.25 225.68,-114.13\"/>\n",
       "</g>\n",
       "<!-- top_k_segments_&#45;&gt;top_k_segments -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>top_k_segments_&#45;&gt;top_k_segments</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M204.5,-71.7C204.5,-63.98 204.5,-54.71 204.5,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208,-46.1 204.5,-36.1 201,-46.1 208,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fa86a6799d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from raglab.retrieval.lib_alexis import dag, generate_split_keys\n",
    "doc_embeddings = dag[:\"doc_embeddings\"]\n",
    "top_k = dag[\"user_query\":\"top_k_segments\"]\n",
    "top_k.dot_digraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"303pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 303.00 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-328 299,-328 299,4 -4,4\"/>\n",
       "<!-- segment_keys -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>segment_keys</title>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">segment_keys</text>\n",
       "</g>\n",
       "<!-- doc_embeddings_ -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>doc_embeddings_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"187.5,-108 71.5,-108 71.5,-72 187.5,-72 187.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"129.5\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">doc_embeddings_</text>\n",
       "</g>\n",
       "<!-- segment_keys&#45;&gt;doc_embeddings_ -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>segment_keys&#45;&gt;doc_embeddings_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.53,-143.7C81.04,-135.05 92.71,-124.45 103.07,-115.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"105.64,-117.42 110.69,-108.1 100.93,-112.24 105.64,-117.42\"/>\n",
       "</g>\n",
       "<!-- documents -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>documents</title>\n",
       "<text text-anchor=\"middle\" x=\"129.5\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">documents</text>\n",
       "</g>\n",
       "<!-- segment_keys_ -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>segment_keys_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-252 0,-252 0,-216 101,-216 101,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">segment_keys_</text>\n",
       "</g>\n",
       "<!-- documents&#45;&gt;segment_keys_ -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>documents&#45;&gt;segment_keys_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.97,-287.7C100.12,-278.97 88.01,-268.24 77.3,-258.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.61,-256.12 69.8,-252.1 74.97,-261.36 79.61,-256.12\"/>\n",
       "</g>\n",
       "<!-- documents&#45;&gt;doc_embeddings_ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>documents&#45;&gt;doc_embeddings_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.5,-287.85C129.5,-250.83 129.5,-163.18 129.5,-118.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133,-118.23 129.5,-108.23 126,-118.23 133,-118.23\"/>\n",
       "</g>\n",
       "<!-- chunker -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>chunker</title>\n",
       "<text text-anchor=\"middle\" x=\"39.5\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">chunker=</text>\n",
       "</g>\n",
       "<!-- chunker&#45;&gt;segment_keys_ -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>chunker&#45;&gt;segment_keys_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.22,-287.7C43.43,-279.98 44.89,-270.71 46.24,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"49.72,-262.53 47.81,-252.1 42.8,-261.44 49.72,-262.53\"/>\n",
       "</g>\n",
       "<!-- segment_keys_&#45;&gt;segment_keys -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>segment_keys_&#45;&gt;segment_keys</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.99,-215.7C51.21,-207.98 51.48,-198.71 51.73,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"55.22,-190.2 52.01,-180.1 48.23,-190 55.22,-190.2\"/>\n",
       "</g>\n",
       "<!-- doc_embeddings -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>doc_embeddings</title>\n",
       "<text text-anchor=\"middle\" x=\"129.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">doc_embeddings</text>\n",
       "</g>\n",
       "<!-- embedding_function -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>embedding_function</title>\n",
       "<text text-anchor=\"middle\" x=\"226.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">embedding_function=</text>\n",
       "</g>\n",
       "<!-- embedding_function&#45;&gt;doc_embeddings_ -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>embedding_function&#45;&gt;doc_embeddings_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.52,-143.7C190.19,-134.8 174.98,-123.82 161.65,-114.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"163.36,-111.12 153.2,-108.1 159.26,-116.79 163.36,-111.12\"/>\n",
       "</g>\n",
       "<!-- doc_embeddings_&#45;&gt;doc_embeddings -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>doc_embeddings_&#45;&gt;doc_embeddings</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.5,-71.7C129.5,-63.98 129.5,-54.71 129.5,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133,-46.1 129.5,-36.1 126,-46.1 133,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fa86a679c70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings.dot_digraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dol import Files\n",
    "f = Files(\"./data_ad\")\n",
    "d ={key: f[key].decode() for key in f} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story.txt': \"Il était une fois dans une petite ville au bord de la mer, vivait un jeune garçon nommé Pierre. Pierre aimait passer ses journées à explorer les plages, à chercher des coquillages brillants et à construire des châteaux de sable.\\n\\nUn jour, alors qu'il se promenait sur la plage, Pierre découvrit une bouteille mystérieuse échouée sur le sable. Il la ramassa avec curiosité et la déboucha pour voir ce qu'elle contenait. À sa grande surprise, une petite carte était enroulée à l'intérieur.\\n\\nLa carte indiquait un endroit secret sur l'île où se trouvait un trésor caché depuis des siècles. Excité par cette découverte, Pierre décida de partir à l'aventure pour trouver le trésor.\\n\\nIl marcha à travers la forêt dense, escalada des rochers escarpés et traversa des rivières tumultueuses. Finalement, après une longue journée d'aventure, Pierre arriva à l'endroit indiqué sur la carte.\\n\\nLà, sous un vieux chêne tordu, il creusa avec enthousiasme et découvrit un coffre rempli de pièces d'or étincelantes et de joyaux étincelants. Pierre ne pouvait pas croire sa chance !\\n\\nIl rentra chez lui en courant pour montrer son trésor à sa famille et à ses amis. À partir de ce jour-là, Pierre fut connu comme le plus grand aventurier de la ville, et chaque fois qu'il retournait à la plage, il se souvenait de l'excitation de sa grande aventure à la recherche du trésor caché.\",\n",
       " 'writers.txt': 'William Shakespeare :\\nMaître des mots et des émotions, Shakespeare explore la condition humaine à travers ses tragédies, comédies et sonnets intemporels.\\nSon langage poétique et ses personnages complexes résonnent encore aujourd\\'hui, captivant les lecteurs à travers les siècles.\\nJane Austen :\\nAusten est connue pour ses romans sociaux délicieusement satiriques, peignant avec subtilité les intrications de la vie et de l\\'amour dans l\\'Angleterre du XIXe siècle.\\nSon style ironique et son humour mordant offrent des commentaires perspicaces sur la société de son époque, tout en créant des héroïnes mémorables et des histoires intemporelles.\\nCharles Dickens :\\nDickens est célèbre pour ses descriptions vivantes de la vie victorienne, mettant en lumière les injustices sociales et les luttes des classes à travers ses romans captivants.\\nSon utilisation magistrale du langage et ses personnages inoubliables, comme Ebenezer Scrooge et Oliver Twist, continuent d\\'inspirer et d\\'émerveiller les lecteurs du monde entier.\\nVirginia Woolf :\\nWoolf est reconnue pour ses expérimentations stylistiques audacieuses et sa prose lyrique, explorant les thèmes de la féminité, de la créativité et de la perception de soi.\\nSes romans, tels que \"Mrs. Dalloway\" et \"To the Lighthouse\", offrent des perspectives profondes sur la condition humaine, tout en repoussant les limites de la narration moderne.\\nGabriel García Márquez :\\nMárquez est célèbre pour son style magique réaliste, mêlant le surnaturel et le quotidien dans des récits envoûtants qui capturent l\\'essence même de la culture latino-américaine.\\nSon chef-d\\'œuvre, \"Cent ans de solitude\", est salué comme l\\'un des plus grands romans du XXe siècle, explorant les thèmes de la mémoire, de l\\'amour et de la destinée.\\nToni Morrison :\\nMorrison explore les complexités de la race, de l\\'identité et de l\\'héritage culturel dans ses œuvres puissantes et poignantes, offrant des réflexions profondes sur l\\'expérience afro-américaine.\\nSes romans, comme \"Beloved\" et \"The Bluest Eye\", sont acclamés pour leur prose lyrique et leur exploration audacieuse des traumatismes historiques et personnels.\\nHermann Hesse :\\nHesse est connu pour ses romans philosophiques et spirituels, explorant les questions de l\\'identité, de la quête de soi et de la recherche de la signification dans un monde en évolution.\\nSes œuvres emblématiques, telles que \"Le Loup des Steppes\" et \"Siddhartha\", offrent des réflexions profondes sur la nature de l\\'existence humaine et le chemin vers l\\'illumination.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "_generate_split_keys =  partial(generate_split_keys, chunk_overlap=40, chunk_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embed = doc_embeddings(documents=d, chunker = _generate_split_keys) # TDODO add semantic chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "pipeline = partial(top_k, doc_embeddings=doc_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = {\n",
    "    \"Une personne qui habite une ville côtière\": \"dans une petite ville au bord de la mer, vivait un jeune garçon nommé Pierre\",\n",
    "    \"quel est le passe temps préféré du protagoniste\": \"Pierre aimait passer ses journées à explorer les plages, à chercher des coquillages brillants et à construire des châteaux de sable\",\n",
    "    \"Pierre aperçois un objet lors d'une promenade, quel est il?\": \"Pierre découvrit une bouteille mystérieuse\",\n",
    "    \"Que contenait la bouteille?\": \"petite carte était enroulée à l'intérieur\",\n",
    "    \"Depuis combien de temps le trésor était-il caché?\": \"un trésor caché depuis des siècles\",\n",
    "    \"Pierre pars chercher le trésor\": \"Pierre décida de partir à l'aventure\",\n",
    "    \"Obstacles naturels sur le parcours\": \"forêt dense, escalada des rochers escarpés et traversa des rivières tumultueuses\",\n",
    "    \"Combien de temps dur le trajet\": \"une longue journée\",\n",
    "    \"contenu du trésor est magnigifique\": \"rempli de pièces d'or étincelantes et de joyaux étincelants\",\n",
    "    \"a quels membre de son entourage partage-il la découverte?\": \"sa famille et à ses amis\",\n",
    "    \"Quel est alors la réputation de Pierre dans sa ville\": \"connu comme le plus grand aventurier de la ville\",\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      " Query: Une personne qui habite une ville côtière\n",
      "Expected: dans une petite ville au bord de la mer, vivait un jeune garçon nommé Pierre\n",
      "correct!\n",
      "Predicted: Il était une fois dans une petite ville au bord de la mer, vivait un jeune garçon nommé Pierre. Pierre aimait passer ses journées à explorer les plages, à chercher des coquillages brillants et à construire des châteaux de sable.\n",
      "\n",
      "-------------\n",
      " Query: quel est le passe temps préféré du protagoniste\n",
      "Expected: Pierre aimait passer ses journées à explorer les plages, à chercher des coquillages brillants et à construire des châteaux de sable\n",
      "Predicted: Il rentra chez lui en courant pour montrer son trésor à sa famille et à ses amis. À partir de ce jour-là, Pierre fut connu comme le plus grand aventurier de la ville, et chaque fois qu'il retournait à la plage, il se souvenait de l'excitation de sa grande aventure à la recherche du trésor caché.\n",
      "\n",
      "-------------\n",
      " Query: Pierre aperçois un objet lors d'une promenade, quel est il?\n",
      "Expected: Pierre découvrit une bouteille mystérieuse\n",
      "correct!\n",
      "Predicted: Un jour, alors qu'il se promenait sur la plage, Pierre découvrit une bouteille mystérieuse échouée sur le sable. Il la ramassa avec curiosité et la déboucha pour voir ce qu'elle contenait. À sa grande surprise, une petite carte était enroulée à l'intérieur.\n",
      "\n",
      "-------------\n",
      " Query: Que contenait la bouteille?\n",
      "Expected: petite carte était enroulée à l'intérieur\n",
      "correct!\n",
      "Predicted: Un jour, alors qu'il se promenait sur la plage, Pierre découvrit une bouteille mystérieuse échouée sur le sable. Il la ramassa avec curiosité et la déboucha pour voir ce qu'elle contenait. À sa grande surprise, une petite carte était enroulée à l'intérieur.\n",
      "\n",
      "-------------\n",
      " Query: Depuis combien de temps le trésor était-il caché?\n",
      "Expected: un trésor caché depuis des siècles\n",
      "correct!\n",
      "Predicted: La carte indiquait un endroit secret sur l'île où se trouvait un trésor caché depuis des siècles. Excité par cette découverte, Pierre décida de partir à l'aventure pour trouver le trésor.\n",
      "\n",
      "-------------\n",
      " Query: Pierre pars chercher le trésor\n",
      "Expected: Pierre décida de partir à l'aventure\n",
      "Predicted: Il rentra chez lui en courant pour montrer son trésor à sa famille et à ses amis. À partir de ce jour-là, Pierre fut connu comme le plus grand aventurier de la ville, et chaque fois qu'il retournait à la plage, il se souvenait de l'excitation de sa grande aventure à la recherche du trésor caché.\n",
      "\n",
      "-------------\n",
      " Query: Obstacles naturels sur le parcours\n",
      "Expected: forêt dense, escalada des rochers escarpés et traversa des rivières tumultueuses\n",
      "correct!\n",
      "Predicted: Il marcha à travers la forêt dense, escalada des rochers escarpés et traversa des rivières tumultueuses. Finalement, après une longue journée d'aventure, Pierre arriva à l'endroit indiqué sur la carte.\n",
      "\n",
      "-------------\n",
      " Query: Combien de temps dur le trajet\n",
      "Expected: une longue journée\n",
      "correct!\n",
      "Predicted: Il marcha à travers la forêt dense, escalada des rochers escarpés et traversa des rivières tumultueuses. Finalement, après une longue journée d'aventure, Pierre arriva à l'endroit indiqué sur la carte.\n",
      "\n",
      "-------------\n",
      " Query: contenu du trésor est magnigifique\n",
      "Expected: rempli de pièces d'or étincelantes et de joyaux étincelants\n",
      "correct!\n",
      "Predicted: Là, sous un vieux chêne tordu, il creusa avec enthousiasme et découvrit un coffre rempli de pièces d'or étincelantes et de joyaux étincelants. Pierre ne pouvait pas croire sa chance !\n",
      "\n",
      "-------------\n",
      " Query: a quels membre de son entourage partage-il la découverte?\n",
      "Expected: sa famille et à ses amis\n",
      "correct!\n",
      "Predicted: Il rentra chez lui en courant pour montrer son trésor à sa famille et à ses amis. À partir de ce jour-là, Pierre fut connu comme le plus grand aventurier de la ville, et chaque fois qu'il retournait à la plage, il se souvenait de l'excitation de sa grande aventure à la recherche du trésor caché.\n",
      "\n",
      "-------------\n",
      " Query: Quel est alors la réputation de Pierre dans sa ville\n",
      "Expected: connu comme le plus grand aventurier de la ville\n",
      "correct!\n",
      "Predicted: Il rentra chez lui en courant pour montrer son trésor à sa famille et à ses amis. À partir de ce jour-là, Pierre fut connu comme le plus grand aventurier de la ville, et chaque fois qu'il retournait à la plage, il se souvenait de l'excitation de sa grande aventure à la recherche du trésor caché.\n",
      "\n",
      "Score: 9/11\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for query, responce in test_set.items():\n",
    "    print(f\"\\n-------------\\n Query: {query}\")\n",
    "    print(f\"Expected: {responce}\")\n",
    "    res = pipeline(user_query=query, k=1)\n",
    "    segment_key=res[0]\n",
    "    if responce in d[segment_key[0]][segment_key[1]:segment_key[2]]:\n",
    "        score += 1\n",
    "        print(\"correct!\")\n",
    "    print(f\"Predicted: {d[segment_key[0]][segment_key[1]:segment_key[2]]}\")\n",
    "\n",
    "print(f\"\\nScore: {score}/{len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump .tsv file to save vectors\n",
    "vectors = list(doc_embed.values()) + dag[\"user_query\":\"query_embedding\"](user_query=\"Une personne qui habite une ville côtière\")\n",
    "labels = list(doc_embed.keys()) + [\"Une personne qui habite une ville côtière\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"a \\n\".replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25\n",
      "[ 0.263606   -0.16116216  0.24300912] Il était une fois dans une petite ville au bord de la mer, vivait un jeune garçon nommé Pierre. Pierre aimait passer ses journées à explorer les plages, à chercher des coquillages brillants et à\n",
      "[ 0.15252536 -0.03040171 -0.14722567] chercher des coquillages brillants et à construire des châteaux de sable.\n",
      "[ 0.32028301 -0.09492968  0.2574581 ] Un jour, alors qu'il se promenait sur la plage, Pierre découvrit une bouteille mystérieuse échouée sur le sable. Il la ramassa avec curiosité et la déboucha pour voir ce qu'elle contenait. À sa\n",
      "[ 0.21093002  0.05010822 -0.19036478] pour voir ce qu'elle contenait. À sa grande surprise, une petite carte était enroulée à l'intérieur.\n",
      "[ 0.2480553   0.02308763 -0.13970906] La carte indiquait un endroit secret sur l'île où se trouvait un trésor caché depuis des siècles. Excité par cette découverte, Pierre décida de partir à l'aventure pour trouver le trésor.\n",
      "[0.31339917 0.07151561 0.13113321] Il marcha à travers la forêt dense, escalada des rochers escarpés et traversa des rivières tumultueuses. Finalement, après une longue journée d'aventure, Pierre arriva à l'endroit indiqué sur la\n",
      "[ 0.22884828  0.12577959 -0.23783656] arriva à l'endroit indiqué sur la carte.\n",
      "[ 0.20117422 -0.02500875 -0.132472  ] Là, sous un vieux chêne tordu, il creusa avec enthousiasme et découvrit un coffre rempli de pièces d'or étincelantes et de joyaux étincelants. Pierre ne pouvait pas croire sa chance !\n",
      "[ 0.25308546 -0.09073018  0.10249982] Il rentra chez lui en courant pour montrer son trésor à sa famille et à ses amis. À partir de ce jour-là, Pierre fut connu comme le plus grand aventurier de la ville, et chaque fois qu'il retournait\n",
      "[ 0.21621904 -0.0244193  -0.08600233] ville, et chaque fois qu'il retournait à la plage, il se souvenait de l'excitation de sa grande aventure à la recherche du trésor caché.\n",
      "[-0.16087904 -0.08034612 -0.01980044] William Shakespeare :\n",
      "Maître des mots et des émotions, Shakespeare explore la condition humaine à travers ses tragédies, comédies et sonnets intemporels.\n",
      "[-0.19453476 -0.13977081 -0.00670264] Son langage poétique et ses personnages complexes résonnent encore aujourd'hui, captivant les lecteurs à travers les siècles.\n",
      "Jane Austen :\n",
      "[-0.21924042 -0.16057536 -0.05316879] Jane Austen :\n",
      "Austen est connue pour ses romans sociaux délicieusement satiriques, peignant avec subtilité les intrications de la vie et de l'amour dans l'Angleterre du XIXe siècle.\n",
      "[-0.18619855 -0.17371183 -0.04401715] Son style ironique et son humour mordant offrent des commentaires perspicaces sur la société de son époque, tout en créant des héroïnes mémorables et des histoires intemporelles.\n",
      "Charles Dickens :\n",
      "[-0.21838096 -0.20192925 -0.07560443] Charles Dickens :\n",
      "Dickens est célèbre pour ses descriptions vivantes de la vie victorienne, mettant en lumière les injustices sociales et les luttes des classes à travers ses romans captivants.\n",
      "[-0.18508492 -0.15983911 -0.01524076] Son utilisation magistrale du langage et ses personnages inoubliables, comme Ebenezer Scrooge et Oliver Twist, continuent d'inspirer et d'émerveiller les lecteurs du monde entier.\n",
      "Virginia Woolf :\n",
      "[-0.18321617 -0.00880384 -0.01703883] Virginia Woolf :\n",
      "Woolf est reconnue pour ses expérimentations stylistiques audacieuses et sa prose lyrique, explorant les thèmes de la féminité, de la créativité et de la perception de soi.\n",
      "[-0.1574739   0.07028965  0.03617117] Ses romans, tels que \"Mrs. Dalloway\" et \"To the Lighthouse\", offrent des perspectives profondes sur la condition humaine, tout en repoussant les limites de la narration moderne.\n",
      "[-0.12534329  0.07929494  0.04038205] Gabriel García Márquez :\n",
      "[-0.10687532  0.10409119 -0.00323002] Márquez est célèbre pour son style magique réaliste, mêlant le surnaturel et le quotidien dans des récits envoûtants qui capturent l'essence même de la culture latino-américaine.\n",
      "[-0.15798851  0.1333356   0.09113709] Son chef-d'œuvre, \"Cent ans de solitude\", est salué comme l'un des plus grands romans du XXe siècle, explorant les thèmes de la mémoire, de l'amour et de la destinée.\n",
      "Toni Morrison :\n",
      "[-0.1161076   0.22446664  0.05027217] Morrison explore les complexités de la race, de l'identité et de l'héritage culturel dans ses œuvres puissantes et poignantes, offrant des réflexions profondes sur l'expérience afro-américaine.\n",
      "[-0.17130831  0.12941355  0.13693725] Ses romans, comme \"Beloved\" et \"The Bluest Eye\", sont acclamés pour leur prose lyrique et leur exploration audacieuse des traumatismes historiques et personnels.\n",
      "Hermann Hesse :\n",
      "[-0.12135431  0.16221461  0.06020221] Hesse est connu pour ses romans philosophiques et spirituels, explorant les questions de l'identité, de la quête de soi et de la recherche de la signification dans un monde en évolution.\n",
      "[-0.10413979  0.1780309   0.01921128] Ses œuvres emblématiques, telles que \"Le Loup des Steppes\" et \"Siddhartha\", offrent des réflexions profondes sur la nature de l'existence humaine et le chemin vers l'illumination.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.00505012 -0.01125633  0.02729863 ... -0.01323909 -0.01103879\n -0.01737863].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# add query embedding\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings_story.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 18\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdag\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_query\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery_embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUne personne qui habite une ville côtière\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]]))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings_metadata_story.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fm:\n\u001b[1;32m     21\u001b[0m     fm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUne personne qui habite une ville côtière\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/sklearn/decomposition/_base.py:145\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    141\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    143\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/sklearn/utils/validation.py:1035\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1029\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1030\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1032\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1034\u001b[0m             )\n\u001b[0;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.00505012 -0.01125633  0.02729863 ... -0.01323909 -0.01103879\n -0.01737863].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# visualisation of embaddings with labels\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(list(doc_embed.values()))\n",
    "sentences = [d[key[0]][key[1]:key[2]] for key in doc_embed.keys()]\n",
    "print(len(principalComponents), len(sentences))\n",
    "sentence_embd = zip(sentences, principalComponents)\n",
    "with open(\"embeddings_story.tsv\", \"w\") as f:\n",
    "    with open(\"embeddings_metadata_story.tsv\", \"w\") as fm:\n",
    "        for k, v in sentence_embd :\n",
    "            fm.write(k.replace(\"\\n\", \"\") + \"\\n\")\n",
    "            f.write(\"\\t\".join([str(x).replace(\"\\n\", \"\") for x in v]) + \"\\n\")\n",
    "            print(v,k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il était une fois dans une petite ville au bord de la mer, vivait un jeune garçon nommé Pierre.\n",
      "\n",
      "\n",
      "vivait un jeune garçon nommé Pierre. Pierre aimait passer ses journées à explorer les plages, à\n",
      "\n",
      "\n",
      "ses journées à explorer les plages, à chercher des coquillages brillants et à construire des\n",
      "\n",
      "\n",
      "brillants et à construire des châteaux de sable.\n",
      "\n",
      "\n",
      "Un jour, alors qu'il se promenait sur la plage, Pierre découvrit une bouteille mystérieuse échouée\n",
      "\n",
      "\n",
      "une bouteille mystérieuse échouée sur le sable. Il la ramassa avec curiosité et la déboucha pour\n",
      "\n",
      "\n",
      "avec curiosité et la déboucha pour voir ce qu'elle contenait. À sa grande surprise, une petite\n",
      "\n",
      "\n",
      "À sa grande surprise, une petite carte était enroulée à l'intérieur.\n",
      "\n",
      "\n",
      "La carte indiquait un endroit secret sur l'île où se trouvait un trésor caché depuis des siècles.\n",
      "\n",
      "\n",
      "un trésor caché depuis des siècles. Excité par cette découverte, Pierre décida de partir à\n",
      "\n",
      "\n",
      "découverte, Pierre décida de partir à l'aventure pour trouver le trésor.\n",
      "\n",
      "\n",
      "Il marcha à travers la forêt dense, escalada des rochers escarpés et traversa des rivières\n",
      "\n",
      "\n",
      "escarpés et traversa des rivières tumultueuses. Finalement, après une longue journée d'aventure,\n",
      "\n",
      "\n",
      "après une longue journée d'aventure, Pierre arriva à l'endroit indiqué sur la carte.\n",
      "\n",
      "\n",
      "Là, sous un vieux chêne tordu, il creusa avec enthousiasme et découvrit un coffre rempli de pièces\n",
      "\n",
      "\n",
      "et découvrit un coffre rempli de pièces d'or étincelantes et de joyaux étincelants. Pierre ne\n",
      "\n",
      "\n",
      "et de joyaux étincelants. Pierre ne pouvait pas croire sa chance !\n",
      "\n",
      "\n",
      "Il rentra chez lui en courant pour montrer son trésor à sa famille et à ses amis. À partir de ce\n",
      "\n",
      "\n",
      "famille et à ses amis. À partir de ce jour-là, Pierre fut connu comme le plus grand aventurier de\n",
      "\n",
      "\n",
      "connu comme le plus grand aventurier de la ville, et chaque fois qu'il retournait à la plage, il se\n",
      "\n",
      "\n",
      "fois qu'il retournait à la plage, il se souvenait de l'excitation de sa grande aventure à la\n",
      "\n",
      "\n",
      "l'excitation de sa grande aventure à la recherche du trésor caché.\n",
      "\n",
      "\n",
      "William Shakespeare :\n",
      "\n",
      "\n",
      "Maître des mots et des émotions, Shakespeare explore la condition humaine à travers ses tragédies,\n",
      "\n",
      "\n",
      "humaine à travers ses tragédies, comédies et sonnets intemporels.\n",
      "\n",
      "\n",
      "Son langage poétique et ses personnages complexes résonnent encore aujourd'hui, captivant les\n",
      "\n",
      "\n",
      "encore aujourd'hui, captivant les lecteurs à travers les siècles.\n",
      "\n",
      "\n",
      "Jane Austen :\n",
      "\n",
      "\n",
      "Austen est connue pour ses romans sociaux délicieusement satiriques, peignant avec subtilité les\n",
      "\n",
      "\n",
      "satiriques, peignant avec subtilité les intrications de la vie et de l'amour dans l'Angleterre du\n",
      "\n",
      "\n",
      "vie et de l'amour dans l'Angleterre du XIXe siècle.\n",
      "\n",
      "\n",
      "Son style ironique et son humour mordant offrent des commentaires perspicaces sur la société de son\n",
      "\n",
      "\n",
      "perspicaces sur la société de son époque, tout en créant des héroïnes mémorables et des histoires\n",
      "\n",
      "\n",
      "héroïnes mémorables et des histoires intemporelles.\n",
      "\n",
      "\n",
      "Charles Dickens :\n",
      "\n",
      "\n",
      "Dickens est célèbre pour ses descriptions vivantes de la vie victorienne, mettant en lumière les\n",
      "\n",
      "\n",
      "vie victorienne, mettant en lumière les injustices sociales et les luttes des classes à travers ses\n",
      "\n",
      "\n",
      "et les luttes des classes à travers ses romans captivants.\n",
      "\n",
      "\n",
      "Son utilisation magistrale du langage et ses personnages inoubliables, comme Ebenezer Scrooge et\n",
      "\n",
      "\n",
      "inoubliables, comme Ebenezer Scrooge et Oliver Twist, continuent d'inspirer et d'émerveiller les\n",
      "\n",
      "\n",
      "d'inspirer et d'émerveiller les lecteurs du monde entier.\n",
      "\n",
      "\n",
      "Virginia Woolf :\n",
      "\n",
      "\n",
      "Woolf est reconnue pour ses expérimentations stylistiques audacieuses et sa prose lyrique,\n",
      "\n",
      "\n",
      "audacieuses et sa prose lyrique, explorant les thèmes de la féminité, de la créativité et de la\n",
      "\n",
      "\n",
      "la féminité, de la créativité et de la perception de soi.\n",
      "\n",
      "\n",
      "Ses romans, tels que \"Mrs. Dalloway\" et \"To the Lighthouse\", offrent des perspectives profondes sur\n",
      "\n",
      "\n",
      "offrent des perspectives profondes sur la condition humaine, tout en repoussant les limites de la\n",
      "\n",
      "\n",
      "tout en repoussant les limites de la narration moderne.\n",
      "\n",
      "\n",
      "Gabriel García Márquez :\n",
      "\n",
      "\n",
      "Márquez est célèbre pour son style magique réaliste, mêlant le surnaturel et le quotidien dans des\n",
      "\n",
      "\n",
      "le surnaturel et le quotidien dans des récits envoûtants qui capturent l'essence même de la culture\n",
      "\n",
      "\n",
      "capturent l'essence même de la culture latino-américaine.\n",
      "\n",
      "\n",
      "Son chef-d'œuvre, \"Cent ans de solitude\", est salué comme l'un des plus grands romans du XXe\n",
      "\n",
      "\n",
      "l'un des plus grands romans du XXe siècle, explorant les thèmes de la mémoire, de l'amour et de la\n",
      "\n",
      "\n",
      "de la mémoire, de l'amour et de la destinée.\n",
      "\n",
      "\n",
      "Toni Morrison :\n",
      "\n",
      "\n",
      "Morrison explore les complexités de la race, de l'identité et de l'héritage culturel dans ses\n",
      "\n",
      "\n",
      "et de l'héritage culturel dans ses œuvres puissantes et poignantes, offrant des réflexions\n",
      "\n",
      "\n",
      "et poignantes, offrant des réflexions profondes sur l'expérience afro-américaine.\n",
      "\n",
      "\n",
      "Ses romans, comme \"Beloved\" et \"The Bluest Eye\", sont acclamés pour leur prose lyrique et leur\n",
      "\n",
      "\n",
      "pour leur prose lyrique et leur exploration audacieuse des traumatismes historiques et personnels.\n",
      "\n",
      "\n",
      "Hermann Hesse :\n",
      "\n",
      "\n",
      "Hesse est connu pour ses romans philosophiques et spirituels, explorant les questions de\n",
      "\n",
      "\n",
      "spirituels, explorant les questions de l'identité, de la quête de soi et de la recherche de la\n",
      "\n",
      "\n",
      "quête de soi et de la recherche de la signification dans un monde en évolution.\n",
      "\n",
      "\n",
      "Ses œuvres emblématiques, telles que \"Le Loup des Steppes\" et \"Siddhartha\", offrent des réflexions\n",
      "\n",
      "\n",
      "et \"Siddhartha\", offrent des réflexions profondes sur la nature de l'existence humaine et le chemin\n",
      "\n",
      "\n",
      "de l'existence humaine et le chemin vers l'illumination.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in doc_embed:\n",
    "    print(d[k[0]][k[1]:k[2]])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
